{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fd332ab5",
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#imports\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import seaborn as sns\n",
    "from datetime import datetime as dt\n",
    "from datetime import timedelta\n",
    "import datetime\n",
    "import re\n",
    "import joblib\n",
    "from urllib.error import HTTPError\n",
    "\n",
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "from sklearn.experimental import enable_halving_search_cv # noqa\n",
    "import warnings\n",
    "from sklearn import tree\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.miscmodels.ordinal_model import OrderedModel\n",
    "import sklearn\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, GradientBoostingRegressor, AdaBoostRegressor\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, GridSearchCV, validation_curve, learning_curve, HalvingGridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression, SGDRegressor, ElasticNet, BayesianRidge, Ridge, Lasso\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.metrics import f1_score, make_scorer, classification_report, precision_score, accuracy_score, recall_score\n",
    "from sklearn.preprocessing import MinMaxScaler, scale, StandardScaler\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neural_network import MLPClassifier, MLPRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "import xgboost as xgb\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "from scipy.stats import poisson\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import requests\n",
    "import itertools as it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "573256bd",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def result(score):\n",
    "    score = re.split('[– -]',score)\n",
    "    if any(c.isalpha() for c in score[1]):\n",
    "        score[1] = str(datetime.datetime.strptime(score[1], '%b').month)\n",
    "        score[0] = score[0].strip('0')\n",
    "    gd = int(score[0]) - int(score[1])\n",
    "    \n",
    "    if gd < 0:\n",
    "        return \"Away\"\n",
    "    if gd > 0:\n",
    "        return \"Home\"\n",
    "    if gd == 0:\n",
    "        return \"Draw\"\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "7b9cbb80",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def prep(df):\n",
    "    features = df.drop(['results', 'date', 'home_shot', 'away_shot', 'home_sot', 'away_sot', 'home_red', 'away_red',\n",
    "                        'home_yellow', 'away_yellow', 'home_goals', 'away_goals', 'ht_home_goals', 'ht_away_goals',\n",
    "                        'home_corner', 'away_corner', 'ht_result', 'home_foul', 'away_foul', 'home', 'away'], axis = 1)\n",
    "    y = df['results'].replace(['Home', 'Draw', 'Away'], range(3)).astype(int)\n",
    "\n",
    "    return features, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c3ab2cae",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#optimisation\n",
    "\n",
    "def optimise(clf, params, X, y, name, metric, rfe, league):\n",
    "    start = time.perf_counter()\n",
    "    if rfe:\n",
    "        params = {'estimator__'+ k:v for k, v in params.items()}\n",
    "        selector = RFE(clf, step = 5)\n",
    "        grid = GridSearchCV(selector, params, scoring = metric, n_jobs = -1, cv = 2)\n",
    "        \n",
    "    else:\n",
    "        grid = GridSearchCV(clf, params, scoring = metric, n_jobs = -1, cv = 2)\n",
    "    grid.fit(X, y)\n",
    "    end = time.perf_counter()\n",
    "    t = (end - start) / 60\n",
    "    joblib.dump(grid, 'Models/' + league + '_' + name + '.pk1')\n",
    "    return grid.best_score_, grid, t\n",
    "\n",
    "def grid(X_input, y, clf, scoring, rfe, league):\n",
    "    best = []\n",
    "    for i in clf:\n",
    "        score, best_clf, t = optimise(i[0], i[1], X_input, y, i[2], scoring, rfe, league)\n",
    "        print(i[2] + ' _____________ ' + str(score) + ' took ' + str(t))\n",
    "        print(best_clf.best_estimator_)\n",
    "        if score <= 0:\n",
    "            score = score + 1\n",
    "        best.append([best_clf, score])\n",
    "    return best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c5a3f86f",
   "metadata": {
    "code_folding": [
     0,
     1,
     12,
     13
    ]
   },
   "outputs": [],
   "source": [
    "#history prediction\n",
    "def histData(league):\n",
    "    hist = pd.read_csv(league + '.csv', encoding = \"ANSI\")\n",
    "    hist = hist[['Home Team', 'Away Team', 'Score']]\n",
    "    hist = hist.astype({'Score': 'string'})\n",
    "\n",
    "    #Score\n",
    "    hist['FTR'] = hist['Score'].apply(result).astype('string')\n",
    "\n",
    "    hist.columns = ['Home', 'Away', 'Score', 'FTR']\n",
    "    return hist\n",
    "\n",
    "def replaceName(name):\n",
    "    names = {\n",
    "        'Hellas Verona': 'HELLAS',\n",
    "        \n",
    "        \n",
    "        'Leeds United': 'LEEDS UTD',\n",
    "        'Leicester City': 'LEICESTER CITY',\n",
    "        'Manchester City': 'MAN CITY',\n",
    "        'Manchester Utd': 'MAN UTD',\n",
    "        'Newcastle Utd': 'NEWCASTLE',\n",
    "        'Norwich City': 'NORWICH',\n",
    "        \n",
    "        'Paris S-G': 'PSG',\n",
    "        'Lens': 'RC LENS',\n",
    "        'Metz': 'FC METZ',\n",
    "        'Reims': 'STADE DE REIMS',\n",
    "        'Rennes': 'STADE RENNAIS',\n",
    "        'Saint-Étienne': 'SAINT-Ã‰TIENNE',\n",
    "        \n",
    "        'Bayern Munich': 'BAYERN',\n",
    "        'Eint Frankfurt': 'FRANKFURT',\n",
    "        'Hertha BSC': 'HERTHA',\n",
    "        'Köln': '1. FC KÃ–LN',\n",
    "        'Mainz 05': 'MAINZ',\n",
    "        'Arminia': 'BIELEFELD', \n",
    "        \n",
    "        'Alavés': 'ALAVÃ‰S',\n",
    "        'Athletic Club': 'ATHLETIC',\n",
    "        'Atlético Madrid': 'ATLETICO MADRID',\n",
    "        'Betis': 'REAL BETIS',\n",
    "        'Celta Vigo': 'CELTA',\n",
    "        'Cádiz': 'CÃ\\x81DIZ CF',\n",
    "        'Sevilla': 'SEVILLA FC'      \n",
    "    }\n",
    "    if name in names.keys():\n",
    "        return names[name]\n",
    "    else:\n",
    "        return name.upper()\n",
    "\n",
    "def histPredict(data):    \n",
    "    predictions = []\n",
    "    for i in data.index:\n",
    "        pred = predict(replaceName(data.iloc[i]['home']), replaceName(data.iloc[i]['away']))\n",
    "        predictions.append(pred)\n",
    "        #print(type(pred), pred)\n",
    "    score = accuracy_score(data['results'], predictions)\n",
    "    return score\n",
    "\n",
    "def predict(team1, team2):\n",
    "    h2h = hist.query('Home == @team1 & Away == @team2').tail(1)\n",
    "    if len(h2h) == 0:\n",
    "        return 0\n",
    "    result = h2h.FTR.iloc[0]\n",
    "    if result == 'Home':\n",
    "        return 0\n",
    "    if result == 'Draw':\n",
    "        return 1\n",
    "    if result == 'Away':\n",
    "        return 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "799f1533",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#poisson predection\n",
    "def poissonPred(team1, team2, endDate, xg, df):\n",
    "    df3 = df.query('date <= @endDate')\n",
    "    \n",
    "    games = len(df3)\n",
    "    \n",
    "    homeGames = df3.query('home == @team1')\n",
    "    awayGames = df3.query('away == @team2')\n",
    "    \n",
    "    if xg == False: \n",
    "        homeGoals = df3['home_goals'].sum()\n",
    "        awayGoals = df3['away_goals'].sum()\n",
    "\n",
    "        team1Goals = homeGames['home_goals'].sum()\n",
    "        team2Goals = awayGames['away_goals'].sum()\n",
    "        \n",
    "        team1GoalsA = homeGames['away_goals'].sum()\n",
    "        team2GoalsA = awayGames['home_goals'].sum()\n",
    "    \n",
    "    else: \n",
    "        homeGoals = df3['home_xg'].sum()\n",
    "        awayGoals = df3['away_xg'].sum()\n",
    "\n",
    "        team1Goals = homeGames['home_xg'].sum()\n",
    "        team2Goals = awayGames['away_xg'].sum()\n",
    "        \n",
    "        team1GoalsA = homeGames['away_xg'].sum()\n",
    "        team2GoalsA = awayGames['home_xg'].sum()\n",
    "\n",
    "    team1Games = len(homeGames)\n",
    "    team2Games = len(awayGames)    \n",
    "    \n",
    "    avgHomeGoals = homeGoals / games\n",
    "    avgAwayGoals = awayGoals / games\n",
    "\n",
    "            \n",
    "    team1AttStr = (team1Goals/team1Games)/avgHomeGoals\n",
    "    team2AttStr = (team2Goals/team2Games)/avgAwayGoals\n",
    "    team1DefStr = (team1GoalsA/team1Games)/avgAwayGoals\n",
    "    team2DefStr = (team2GoalsA/team2Games)/avgHomeGoals\n",
    "    team1ExpGoal = team1AttStr * team2DefStr * avgHomeGoals\n",
    "    team2ExpGoal = team2AttStr * team1DefStr * avgAwayGoals\n",
    "    \n",
    "    team1Table = []\n",
    "    score = 5\n",
    "    for i in range(score):\n",
    "        team1Table.append(poisson.pmf(i, team1ExpGoal))\n",
    "    \n",
    "    team2Table = []\n",
    "    for i in range(score):\n",
    "        team2Table.append(poisson.pmf(i, team2ExpGoal))\n",
    "    \n",
    "    probs = np.array([team1Table]).T.dot(np.array([team2Table]))\n",
    "    home = 0\n",
    "    draw = 0\n",
    "    away = 0\n",
    "    for i in range(score):\n",
    "        for j in range(score):\n",
    "            if i > j:\n",
    "                home += probs[i][j]\n",
    "            if i == j:\n",
    "                draw += probs[i][j]\n",
    "            if i < j:\n",
    "                away += probs[i][j]\n",
    "\n",
    "    if np.isnan(home):\n",
    "        home = 0\n",
    "    if np.isnan(away):\n",
    "        away = 0\n",
    "    if np.isnan(draw):\n",
    "        draw = 0\n",
    "    return [home, draw, away]\n",
    "\n",
    "def poiAcc(data, xg):\n",
    "    predictions = []\n",
    "    for i in data.index:\n",
    "        probs = poissonPred(data.iloc[i]['home'], data.iloc[i]['away'], data.iloc[-1]['date'], xg, data)\n",
    "        pred = np.array(probs).argmax()\n",
    "        predictions.append(pred)\n",
    "    score = accuracy_score(data['results'], predictions)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9acdc5dc",
   "metadata": {
    "code_folding": [
     0,
     1
    ]
   },
   "outputs": [],
   "source": [
    "def roundPred(num):\n",
    "    if abs(num - 1) < 0.33:\n",
    "        return 1\n",
    "    if num >= 1:\n",
    "        return 2\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f431d2cd",
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def importance(model):\n",
    "    resultGrid = joblib.load(j + model + '.pk1')\n",
    "    perm = PermutationImportance(resultGrid.best_estimator_, random_state=1).fit(X_train, y_train)\n",
    "    \n",
    "    shap.initjs()\n",
    "    explainer = shap.TreeExplainer(resultGrid.best_estimator_.fit(X_train, y_train))\n",
    "    shap_values = explainer.shap_values(X_train)\n",
    "    shap.force_plot(explainer.expected_value, shap_values[0,:], X_train.iloc[0,:])\n",
    "    shap.summary_plot(shap_values, X_train, plot_type=\"bar\")\n",
    "    return eli5.show_weights(perm, feature_names = dummies(X).columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7768f924",
   "metadata": {
    "code_folding": [
     0,
     1,
     19
    ]
   },
   "outputs": [],
   "source": [
    "#plot\n",
    "def plot_validation_curve(est, X, y, p_name, p_range, title):\n",
    "    train_scores, test_scores = validation_curve(estimator=est,\n",
    "                                             X=X, y=y,\n",
    "                                             cv=5,\n",
    "    param_name=p_name, param_range=p_range)\n",
    "    train_mean = np.mean(train_scores, axis=1)\n",
    "    test_mean = np.mean(test_scores, axis=1)\n",
    "\n",
    "    plt.plot(p_range, train_mean,\n",
    "             color='blue', label='Training Accuracy')\n",
    "    plt.plot(p_range, test_mean,\n",
    "             color='green', label='Validation Accuracy')\n",
    "    plt.xlabel(p_name)\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title(title)\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "def plot_decision_boundaries(X, y, model, title):\n",
    "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.1), np.arange(y_min, y_max, 0.1))\n",
    "    Z = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    colors = {0.0:'blue', 1.0:'darkcyan', 2.0:'green'}  \n",
    "    print(Z.shape)\n",
    "    print(Z.ravel().shape)\n",
    "    print(X[:, 0].shape)\n",
    "    print(X[:, 1].shape)\n",
    "    \n",
    "    colored_labels = np.array([colors[xi] for xi in y]) #Z.ravel()\n",
    "    plt.contourf(xx, yy, Z, cmap='viridis')\n",
    "\n",
    "\n",
    "    cb = plt.colorbar()\n",
    "    plt.xlim(xx.min(), xx.max())\n",
    "    plt.ylim(yy.min(), yy.max())\n",
    "    plt.xlabel(\"PC1\")\n",
    "    plt.ylabel(\"PC2\")\n",
    "    plt.title(title)\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=colored_labels, cmap='viridis', s=10)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "71080e7e",
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#models\n",
    "def classifiers(feat):\n",
    "    \n",
    "    random = [RandomForestClassifier(max_features = None), { \n",
    "            'n_estimators': range(1, 32, 10),\n",
    "            'max_depth' : range(2, 5),\n",
    "            'criterion' :['gini', 'entropy']}, 'random']\n",
    "    \n",
    "    decision = [DecisionTreeClassifier(), {\n",
    "            'criterion' :['gini', 'entropy']}, 'decision']\n",
    "    \n",
    "    logis = [LogisticRegression(max_iter = 1000, penalty = 'l2'), {\n",
    "            'solver' : ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "            'C' : [0.01,0.1, 1]}, 'logistic']\n",
    "\n",
    "    knn = [KNeighborsClassifier(), {\n",
    "            'n_neighbors': range(15, 40, 4),\n",
    "            'weights': ['uniform', 'distance']}, 'knn']\n",
    "\n",
    "    svc_linear = [svm.SVC(kernel = 'linear', tol = 0.01), {\n",
    "            }, 'svc_linear']\n",
    "    \n",
    "    svc_sigmoid = [svm.SVC(kernel = 'sigmoid'), {\n",
    "            'C': np.logspace(-2, 1, 5),\n",
    "            'gamma': np.logspace(-4, 1, 5)}, 'svc_sigmoid']\n",
    "    \n",
    "    svc = [svm.SVC(), {\n",
    "            'C': np.logspace(-1, 2, 5),\n",
    "            'gamma': np.logspace(-4, 0, 5)}, 'svc']\n",
    "\n",
    "    xg = [xgb.XGBClassifier(eval_metric = 'merror', use_label_encoder=False), {\n",
    "            'min_child_weight': [2, 4],\n",
    "            'max_depth': [1, 2, 3],\n",
    "            'n_estimators': range(50, 251, 50),}, 'xgboost']\n",
    "    \n",
    "    bayes = [GaussianNB(), {\n",
    "            'var_smoothing': np.logspace(-2 ,1, 3)}, 'bayes']\n",
    "    \n",
    "    MLP = [MLPClassifier(max_iter = 10000, tol = 0.001), {\n",
    "            'solver': ['sgd', 'adam'],\n",
    "            'alpha': [1, 2, 3],\n",
    "            'learning_rate': ['constant', 'invscaling', 'adaptive'],\n",
    "            'activation': [\"relu\", \"tanh\"],\n",
    "            'hidden_layer_sizes':[(80, 80, 80, 80)]}, 'mlp']\n",
    "    \n",
    "    ada = [AdaBoostClassifier(algorithm = 'SAMME.R'), {\n",
    "            'n_estimators': range(50, 251, 50),\n",
    "            'learning_rate': [0.1, 0.5, 1]}, 'ada']\n",
    "    \n",
    "    gbc = [GradientBoostingClassifier(tol = 0.001), {\n",
    "            'n_estimators': [50, 100, 150, 200],\n",
    "            'learning_rate': [0.1],\n",
    "            'max_depth': [3, 4]}, 'gbc']\n",
    "    \n",
    "    if feat:\n",
    "        clfs = [random, decision, logis, xg, ada, gbc]\n",
    "        #clfs = []\n",
    "    else:\n",
    "        clfs = [knn, svc_sigmoid, svc, bayes, MLP]\n",
    "        #clfs = []\n",
    "\n",
    "    return clfs\n",
    "\n",
    "def regressors(feat):\n",
    "    \n",
    "    linear = [LinearRegression(), {}, 'linear']\n",
    "\n",
    "    knn_R = [KNeighborsRegressor(), {\n",
    "            'n_neighbors': range(5, 30, 3),\n",
    "            'weights': ['uniform', 'distance']}, 'knn_R']\n",
    "\n",
    "    svc_linear_R = [svm.SVR(kernel = 'linear', tol=0.01), {\n",
    "            }, 'svc_linear_R']\n",
    "    \n",
    "    svc_sigmoid_R = [svm.SVR(kernel = 'sigmoid'), {\n",
    "            'C': np.logspace(-3, 1, 6),\n",
    "            'gamma': ['scale', 'auto']}, 'svc_sigmoid_R']\n",
    "    \n",
    "    svc_R = [svm.SVR(), {\n",
    "            'C': np.logspace(-2, 1, 5),\n",
    "            'gamma': ['scale', 'auto']}, 'svc_R']\n",
    "\n",
    "    xg_R = [xgb.XGBRegressor(eval_metric = 'merror', use_label_encoder=False), {\n",
    "            'learning_rate': [0.03, 0.05],\n",
    "            'max_depth': [1, 2],\n",
    "            'min_child_weight': [3, 4],\n",
    "            'n_estimators': range(50, 251, 50)}, 'xgboost_R']\n",
    "\n",
    "    MLP_R = [MLPRegressor(max_iter = 10000, tol = 0.001), {\n",
    "            'solver': ['lbfgs', 'adam'],\n",
    "            'alpha': [2, 4, 6],\n",
    "            'learning_rate': ['constant', 'adaptive'],\n",
    "            'activation': ['tanh'],\n",
    "            'hidden_layer_sizes':[(80, 80, 80, 80)]}, 'mlp_R']\n",
    "    \n",
    "    ada_R = [AdaBoostRegressor(loss='square'), {\n",
    "            'n_estimators': range(50, 251, 50),\n",
    "            'learning_rate': np.logspace(-1, 0.5, 5)}, 'ada_R']\n",
    "    \n",
    "    gbc_R = [GradientBoostingRegressor(tol = 0.001), {\n",
    "            'n_estimators': [50, 100, 150, 200, 250],\n",
    "            'learning_rate': [0.1, 0,2],\n",
    "            'max_depth': [3, 4]}, 'gbc_R']\n",
    "    \n",
    "    if feat:\n",
    "        regs = [linear, xg_R, ada_R, gbc_R]\n",
    "        #regs = []\n",
    "    else:\n",
    "        regs = [knn_R, svc_R, svc_sigmoid_R, MLP_R]\n",
    "        #regs = [svc_R, svc_sigmoid_R]\n",
    "    return regs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "556f3b8b",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def localProcessed(league):\n",
    "        df = pd.read_csv('local_' + league + '_processed.csv')\n",
    "        df = df.drop(['Unnamed: 0'], axis = 1)\n",
    "        df = df.reset_index(drop = True)\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6940df57",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#load data\n",
    "\n",
    "leagues = {\n",
    "    'prem':[],\n",
    "    'ligue':[],\n",
    "    'bundes':[],\n",
    "    'serie':[],\n",
    "    'laliga':[],\n",
    "    'combined': []}\n",
    "\n",
    "for i in leagues:\n",
    "    df = localProcessed(i)\n",
    "    df['results'] = df['results'].replace(['H', 'D', 'A'], range(3))\n",
    "    df['ht_result'] = df['ht_result'].replace(['H', 'D', 'A'], range(3))\n",
    "    leagues[i].append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "53ecee86",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#combined history data\n",
    "hist = pd.DataFrame()\n",
    "for i in list(leagues.keys())[0:-1]:\n",
    "    hist = pd.concat([hist, histData(i)])\n",
    "hist.to_csv('local_hist.csv')\n",
    "hist.columns = ['Home', 'Away', 'Score', 'FTR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b58dda9f",
   "metadata": {
    "code_folding": [],
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knn _____________ 0.5133547008547008 took 0.0748428649999975\n",
      "KNeighborsClassifier(n_neighbors=23, weights='distance')\n",
      "svc_sigmoid _____________ 0.5491452991452992 took 0.017363033333322165\n",
      "SVC(C=1.7782794100389228, gamma=0.0017782794100389228, kernel='sigmoid')\n",
      "svc _____________ 0.5496794871794872 took 0.03266537166667452\n",
      "SVC(C=17.78279410038923, gamma=0.0001)\n",
      "bayes _____________ 0.5256410256410257 took 0.0002886916666587543\n",
      "GaussianNB(var_smoothing=0.31622776601683794)\n",
      "mlp _____________ 0.530982905982906 took 2.5574334799999936\n",
      "MLPClassifier(activation='tanh', alpha=1, hidden_layer_sizes=(80, 80, 80, 80),\n",
      "              max_iter=10000, solver='sgd', tol=0.001)\n",
      "random _____________ 0.5699786324786325 took 0.29943148833332695\n",
      "RFE(estimator=RandomForestClassifier(max_depth=2, max_features=None,\n",
      "                                     n_estimators=21),\n",
      "    step=5)\n",
      "decision _____________ 0.43696581196581197 took 0.02441454166666214\n",
      "RFE(estimator=DecisionTreeClassifier(), step=5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic _____________ 0.5592948717948718 took 0.688886191666658\n",
      "RFE(estimator=LogisticRegression(C=0.01, max_iter=1000), step=5)\n",
      "xgboost _____________ 0.5496794871794872 took 3.103102113333322\n",
      "RFE(estimator=XGBClassifier(base_score=None, booster=None,\n",
      "                            colsample_bylevel=None, colsample_bynode=None,\n",
      "                            colsample_bytree=None, enable_categorical=False,\n",
      "                            eval_metric='merror', gamma=None, gpu_id=None,\n",
      "                            importance_type=None, interaction_constraints=None,\n",
      "                            learning_rate=None, max_delta_step=None,\n",
      "                            max_depth=1, min_child_weight=4, missing=nan,\n",
      "                            monotone_constraints=None, n_estimators=50,\n",
      "                            n_jobs=None, num_parallel_tree=None, predictor=None,\n",
      "                            random_state=None, reg_alpha=None, reg_lambda=None,\n",
      "                            scale_pos_weight=None, subsample=None,\n",
      "                            tree_method=None, use_label_encoder=False,\n",
      "                            validate_parameters=None, verbosity=None),\n",
      "    step=5)\n",
      "ada _____________ 0.5667735042735043 took 0.8474657916666577\n",
      "RFE(estimator=AdaBoostClassifier(learning_rate=0.1), step=5)\n",
      "gbc _____________ 0.5357905982905983 took 3.264559163333327\n",
      "RFE(estimator=GradientBoostingClassifier(max_depth=4, n_estimators=50,\n",
      "                                         tol=0.001),\n",
      "    step=5)\n",
      "knn_R _____________ -0.7095455292570677 took 0.008698903333333874\n",
      "KNeighborsRegressor(n_neighbors=26)\n",
      "svc_R _____________ -0.6719681830125361 took 0.0486372883333388\n",
      "SVR(C=0.31622776601683794)\n",
      "svc_sigmoid_R _____________ -0.6725011525253184 took 0.011465018333334834\n",
      "SVR(C=0.039810717055349734, kernel='sigmoid')\n",
      "mlp_R _____________ -0.6787484200575331 took 6.323798308333335\n",
      "MLPRegressor(activation='tanh', alpha=6, hidden_layer_sizes=(80, 80, 80, 80),\n",
      "             learning_rate='adaptive', max_iter=10000, tol=0.001)\n",
      "linear _____________ -0.6812237084876549 took 0.004719075000002704\n",
      "RFE(estimator=LinearRegression(), step=5)\n",
      "xgboost_R _____________ -0.6719913257039192 took 1.501193349999994\n",
      "RFE(estimator=XGBRegressor(base_score=None, booster=None,\n",
      "                           colsample_bylevel=None, colsample_bynode=None,\n",
      "                           colsample_bytree=None, enable_categorical=False,\n",
      "                           eval_metric='merror', gamma=None, gpu_id=None,\n",
      "                           importance_type=None, interaction_constraints=None,\n",
      "                           learning_rate=0.05, max_delta_step=None, max_depth=1,\n",
      "                           min_child_weight=3, missing=nan,\n",
      "                           monotone_constraints=None, n_estimators=250,\n",
      "                           n_jobs=None, num_parallel_tree=None, predictor=None,\n",
      "                           random_state=None, reg_alpha=None, reg_lambda=None,\n",
      "                           scale_pos_weight=None, subsample=None,\n",
      "                           tree_method=None, use_label_encoder=False,\n",
      "                           validate_parameters=None, verbosity=None),\n",
      "    step=5)\n",
      "ada_R _____________ -0.7054358517384897 took 1.9871033866666645\n",
      "RFE(estimator=AdaBoostRegressor(learning_rate=0.1, loss='square'), step=5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
      "20 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "20 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_rfe.py\", line 222, in fit\n",
      "    return self._fit(X, y, **fit_params)\n",
      "  File \"C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\feature_selection\\_rfe.py\", line 283, in _fit\n",
      "    estimator.fit(X[:, features], y, **fit_params)\n",
      "  File \"C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 525, in fit\n",
      "    self._check_params()\n",
      "  File \"C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_gb.py\", line 274, in _check_params\n",
      "    raise ValueError(\n",
      "ValueError: learning_rate must be greater than 0 but was 0\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [-0.67443251 -0.68028353 -0.68592454 -0.68955032 -0.69870519 -0.67624815\n",
      " -0.67575988 -0.69244861 -0.6991565  -0.69749246         nan         nan\n",
      "         nan         nan         nan         nan         nan         nan\n",
      "         nan         nan -0.91957284 -0.91957284 -0.91957284 -0.91957284\n",
      " -0.91957284 -1.45023282 -1.12276234 -1.35018433 -1.05862207 -1.17613428]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbc_R _____________ -0.674432507925652 took 2.2587497083333345\n",
      "RFE(estimator=GradientBoostingRegressor(n_estimators=50, tol=0.001), step=5)\n",
      "knn _____________ 0.4878976276614072 took 0.006593416666661748\n",
      "KNeighborsClassifier(n_neighbors=27, weights='distance')\n",
      "svc_sigmoid _____________ 0.5132303985650443 took 0.01760565500000363\n",
      "SVC(C=10.0, gamma=0.0017782794100389228, kernel='sigmoid')\n",
      "svc _____________ 0.5160431804132591 took 0.0334585249999994\n",
      "SVC(C=3.1622776601683795, gamma=0.001)\n",
      "bayes _____________ 0.48676833470140557 took 0.0002697400000063984\n",
      "GaussianNB(var_smoothing=0.31622776601683794)\n",
      "mlp _____________ 0.5199820883876002 took 2.788942584999995\n",
      "MLPClassifier(activation='tanh', alpha=1, hidden_layer_sizes=(80, 80, 80, 80),\n",
      "              max_iter=10000, solver='sgd', tol=0.001)\n",
      "random _____________ 0.5227986704364658 took 0.35150180666666225\n",
      "RFE(estimator=RandomForestClassifier(max_depth=2, max_features=None,\n",
      "                                     n_estimators=11),\n",
      "    step=5)\n",
      "decision _____________ 0.41305140911440125 took 0.022028423333328342\n",
      "RFE(estimator=DecisionTreeClassifier(), step=5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "C:\\Users\\moham\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logistic _____________ 0.523926063296142 took 0.8436086549999952\n",
      "RFE(estimator=LogisticRegression(C=0.01, max_iter=1000, solver='sag'), step=5)\n",
      "xgboost _____________ 0.510415083249729 took 3.479177138333322\n",
      "RFE(estimator=XGBClassifier(base_score=None, booster=None,\n",
      "                            colsample_bylevel=None, colsample_bynode=None,\n",
      "                            colsample_bytree=None, enable_categorical=False,\n",
      "                            eval_metric='merror', gamma=None, gpu_id=None,\n",
      "                            importance_type=None, interaction_constraints=None,\n",
      "                            learning_rate=None, max_delta_step=None,\n",
      "                            max_depth=1, min_child_weight=4, missing=nan,\n",
      "                            monotone_constraints=None, n_estimators=50,\n",
      "                            n_jobs=None, num_parallel_tree=None, predictor=None,\n",
      "                            random_state=None, reg_alpha=None, reg_lambda=None,\n",
      "                            scale_pos_weight=None, subsample=None,\n",
      "                            tree_method=None, use_label_encoder=False,\n",
      "                            validate_parameters=None, verbosity=None),\n",
      "    step=5)\n",
      "ada _____________ 0.5126711357026318 took 0.9322150716666632\n",
      "RFE(estimator=AdaBoostClassifier(learning_rate=0.1, n_estimators=100), step=5)\n",
      "gbc _____________ 0.48002741211402633 took 3.028450771666667\n",
      "RFE(estimator=GradientBoostingClassifier(n_estimators=50, tol=0.001), step=5)\n",
      "knn_R _____________ -0.7077133702432157 took 0.007426851666665849\n",
      "KNeighborsRegressor(n_neighbors=20, weights='distance')\n",
      "svc_R _____________ -0.6716334747770949 took 0.05587691666666312\n",
      "SVR(C=0.31622776601683794)\n",
      "svc_sigmoid_R _____________ -0.6754963931040703 took 0.01289655833334109\n",
      "SVR(C=0.039810717055349734, kernel='sigmoid')\n",
      "mlp_R _____________ -0.6728766806273676 took 6.797304161666656\n",
      "MLPRegressor(activation='tanh', alpha=4, hidden_layer_sizes=(80, 80, 80, 80),\n",
      "             learning_rate='adaptive', max_iter=10000, tol=0.001)\n",
      "linear _____________ -0.6769872494300218 took 0.0022182966666756936\n",
      "RFE(estimator=LinearRegression(), step=5)\n",
      "xgboost_R _____________ -0.6748649260367272 took 1.432841158333334\n",
      "RFE(estimator=XGBRegressor(base_score=None, booster=None,\n",
      "                           colsample_bylevel=None, colsample_bynode=None,\n",
      "                           colsample_bytree=None, enable_categorical=False,\n",
      "                           eval_metric='merror', gamma=None, gpu_id=None,\n",
      "                           importance_type=None, interaction_constraints=None,\n",
      "                           learning_rate=0.05, max_delta_step=None, max_depth=2,\n",
      "                           min_child_weight=4, missing=nan,\n",
      "                           monotone_constraints=None, n_estimators=100,\n",
      "                           n_jobs=None, num_parallel_tree=None, predictor=None,\n",
      "                           random_state=None, reg_alpha=None, reg_lambda=None,\n",
      "                           scale_pos_weight=None, subsample=None,\n",
      "                           tree_method=None, use_label_encoder=False,\n",
      "                           validate_parameters=None, verbosity=None),\n",
      "    step=5)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_21984/355815563.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[0mreg_ret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_pca_scaled\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'neg_mean_absolute_error'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 41\u001b[1;33m     \u001b[0mreg_rfe_ret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreg_rfe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'neg_mean_absolute_error'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     42\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     43\u001b[0m     \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mperf_counter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_21984/4202139894.py\u001b[0m in \u001b[0;36mgrid\u001b[1;34m(X_input, y, clf, scoring, rfe, league)\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[0mbest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m         \u001b[0mscore\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbest_clf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0moptimise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrfe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mleague\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' _____________ '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' took '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbest_clf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_21984/4202139894.py\u001b[0m in \u001b[0;36moptimise\u001b[1;34m(clf, params, X, y, name, metric, rfe, league)\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mgrid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmetric\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mgrid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m     \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mperf_counter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mend\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m60\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    889\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 891\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    892\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    893\u001b[0m             \u001b[1;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1390\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1391\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1392\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1393\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1394\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    836\u001b[0m                     )\n\u001b[0;32m    837\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 838\u001b[1;33m                 out = parallel(\n\u001b[0m\u001b[0;32m    839\u001b[0m                     delayed(_fit_and_score)(\n\u001b[0;32m    840\u001b[0m                         \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbase_estimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1054\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1055\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1056\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1057\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1058\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    933\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    934\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 935\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    936\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    937\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    541\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 542\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    543\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    432\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    433\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 434\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    435\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    436\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    300\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    301\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 302\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    303\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    304\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#ml model\n",
    "#commented line have a runtime of a few hours\n",
    "for i in leagues:\n",
    "    \n",
    "    start = time.perf_counter()\n",
    "    \n",
    "    df = leagues[i][0]\n",
    "    #print(i)\n",
    "    \n",
    "    #df['avg_pos'] = df['avg_pos_home'] / df['avg_pos_away']\n",
    "    #df['avg_pos_diff'] = df['avg_pos_home'] - df['avg_pos_away']\n",
    "    #df['5_form'] = df['home_5_form'] - df['away_5_form']\n",
    "    #df['3_form'] = df['home_3_form'] - df['away_3_form']\n",
    "    #df['1_form'] = df['home_1_form'] - df['away_1_form']\n",
    "    \n",
    "    X, y = prep(df)\n",
    "    \n",
    "    \n",
    "    pca = PCA(0.9)\n",
    "    scaler = StandardScaler()\n",
    "    pipe = Pipeline([('scaler', scaler), ('pca', pca)])\n",
    "    X_pca_scaled = pipe.fit_transform(X)\n",
    "    leagues[i].append(pipe)\n",
    "    \n",
    "    f1 = make_scorer(f1_score, average = 'macro')\n",
    "    \n",
    "    clf = classifiers(False)\n",
    "    \n",
    "    clf_rfe = classifiers(True)\n",
    "    \n",
    "    reg = regressors(False)\n",
    "    \n",
    "    reg_rfe = regressors(True)\n",
    "       \n",
    "    clf_ret = grid(X_pca_scaled, y, clf, 'accuracy', False, i)\n",
    "    \n",
    "    clf_rfe_ret = grid(X, y, clf_rfe, 'accuracy', True, i)\n",
    "    \n",
    "    reg_ret = grid(X_pca_scaled, y, reg, 'neg_mean_absolute_error', False, i)\n",
    "    \n",
    "    reg_rfe_ret = grid(X, y, reg_rfe, 'neg_mean_absolute_error', True, i)\n",
    "        \n",
    "    end = time.perf_counter()\n",
    "    \n",
    "    #print((end - start)/60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85eccd10",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "rep = 5\n",
    "\n",
    "def eval_score(models, pca, acc, X, y):\n",
    "    scores = []\n",
    "    for j in (models):\n",
    "        grid = joblib.load('Models/' + i + '_' + j[2] + '.pk1').best_estimator_\n",
    "        accuracy = []\n",
    "        for n in range(rep):\n",
    "            if pca:\n",
    "                X_pca = pipe.transform(X)\n",
    "                X_train, X_test, y_train, y_test = train_test_split(X_pca, y, test_size=0.2)\n",
    "            else:\n",
    "                X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "    \n",
    "            grid.fit(X_train, y_train)\n",
    "            pred = grid.predict(X_test)\n",
    "            if acc:\n",
    "                score = accuracy_score(pred, y_test)\n",
    "            else:\n",
    "                score = 1 - sklearn.metrics.mean_absolute_error(pred, y_test)\n",
    "            accuracy.append(score)\n",
    "            \n",
    "        mean = np.round(np.array(accuracy).mean(), decimals=2)\n",
    "        var = np.round(np.array(accuracy).var(), decimals=5)\n",
    "        print(j[2], mean, var)\n",
    "        scores.append((mean, var))\n",
    "    return np.array(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dbb3aea",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "results = pd.DataFrame()\n",
    "   \n",
    "for i in leagues:\n",
    "    df = leagues[i][0]\n",
    "    pipe = leagues[i][1]\n",
    "    df['avg_pos'] = df['avg_pos_home'] / df['avg_pos_away']\n",
    "    df['avg_pos_diff'] = df['avg_pos_home'] - df['avg_pos_away']\n",
    "    df['5_form'] = df['home_5_form'] - df['away_5_form']\n",
    "    df['3_form'] = df['home_3_form'] - df['away_3_form']\n",
    "    df['1_form'] = df['home_1_form'] - df['away_1_form']\n",
    "    X, y = prep(df)\n",
    "    one = eval_score(classifiers(True), False, True, X, y)\n",
    "    two = eval_score(classifiers(False), True, True, X, y)\n",
    "    three = eval_score(regressors(True), False, False, X, y)\n",
    "    four = eval_score(regressors(False), True, False, X, y)\n",
    "     \n",
    "    scores = np.vstack((one, two, three, four))\n",
    "    #scores = np.array(scores)\n",
    "    print(scores)\n",
    "    #print(scores.reshape(2,1))\n",
    "    scores = pd.DataFrame(scores)\n",
    "    scores['Mean/Std'] = scores[[0,1]].apply(tuple, axis=1)\n",
    "    scores = pd.DataFrame(scores['Mean/Std'])\n",
    "    results = pd.concat([results, scores], axis = 1)\n",
    "display(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f37b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "clfNames = ['Random Forest', 'Decision Tree', 'Logistic Regression', 'XGBoost', 'AdaBoost', 'Gradient Descent', 'KNN', \n",
    "            'SVC(sigmoid kernel)', 'SVC(RBF kernel)', 'Naive Bayes', 'MLP'] \n",
    "regNames = ['Linear Regression', 'XGBoost', 'AdaBoost', 'Gradient Descent', 'KNN', 'SVM(RBF kernel)',\n",
    "            'SVM(Sigmoid kernel)', 'MLP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796c9f2c",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def eval_score_comb(models, pca, acc, X, y):\n",
    "    scores = []\n",
    "    for j in (models):\n",
    "        grid = joblib.load('Models/' +'combined_' + j[2] + '.pk1').best_estimator_\n",
    "        accuracy = []\n",
    "        for n in range(rep):\n",
    "            if pca:\n",
    "                X_pca = pipe.transform(X)\n",
    "                X_train, X_test, y_train, y_test = train_test_split(X_pca, y, test_size=0.2)\n",
    "            else:\n",
    "                X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "    \n",
    "            grid.fit(X_train, y_train)\n",
    "            pred = grid.predict(X_test)\n",
    "            if acc:\n",
    "                score = accuracy_score(pred, y_test)\n",
    "            else:\n",
    "                score = 1 - sklearn.metrics.mean_absolute_error(pred, y_test)\n",
    "            accuracy.append(score)\n",
    "            \n",
    "        mean = np.round(np.array(accuracy).mean(), decimals=2)\n",
    "        var = np.round(np.array(accuracy).var(), decimals=5)\n",
    "        print(j[2], mean, var)\n",
    "        scores.append((mean, var))\n",
    "    return np.array(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92a5f737",
   "metadata": {
    "code_folding": [
     2
    ]
   },
   "outputs": [],
   "source": [
    "results_comb = pd.DataFrame()\n",
    "\n",
    "for i in leagues:\n",
    "    df = leagues[i][0]\n",
    "    pipe = leagues[i][1]\n",
    "    df['avg_pos'] = df['avg_pos_home'] / df['avg_pos_away']\n",
    "    df['avg_pos_diff'] = df['avg_pos_home'] - df['avg_pos_away']\n",
    "    df['5_form'] = df['home_5_form'] - df['away_5_form']\n",
    "    df['3_form'] = df['home_3_form'] - df['away_3_form']\n",
    "    df['1_form'] = df['home_1_form'] - df['away_1_form']\n",
    "    X, y = prep(df)\n",
    "    one = eval_score_comb(classifiers(True), False, True, X, y)\n",
    "    two = eval_score_comb(classifiers(False), True, True, X, y)\n",
    "    three = eval_score_comb(regressors(True), False, False, X, y)\n",
    "    four = eval_score_comb(regressors(False), True, False, X, y)\n",
    "     \n",
    "    scores = np.vstack((one, two, three, four))\n",
    "    #scores = np.array(scores)\n",
    "    print(scores)\n",
    "    #print(scores.reshape(2,1))\n",
    "    scores = pd.DataFrame(scores)\n",
    "    scores['Mean/Std'] = scores[[0,1]].apply(tuple, axis=1)\n",
    "    scores = pd.DataFrame(scores['Mean/Std'])\n",
    "    results_comb = pd.concat([results_comb, scores], axis = 1)\n",
    "display(results_comb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8265a109",
   "metadata": {},
   "outputs": [],
   "source": [
    "leagueNames = ['Premier League', 'Ligue 1', 'Bundesliga', 'Serie A', 'La Liga', 'Combined leagues']\n",
    "results_comb.columns = leagueNames\n",
    "results_clf = results_comb.iloc[0: len(clfNames)]\n",
    "results_reg = results_comb.iloc[len(clfNames):]\n",
    "results_clf['name'] = clfNames\n",
    "results_reg['name'] = regNames\n",
    "\n",
    "results_clf = results_clf.set_index('name', drop = True)\n",
    "results_clf.index.name = None\n",
    "\n",
    "results_reg = results_reg.set_index('name', drop = True)\n",
    "results_reg.index.name = None\n",
    "\n",
    "display(results_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05d24cf4",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#other methods\n",
    "data = leagues['combined'][0]\n",
    "\n",
    "print(histPredict(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05dabc8",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "print(poiAcc(data, False)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e53871",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = data.copy()\n",
    "pipe = leagues['combined'][1]\n",
    "df['avg_pos'] = df['avg_pos_home'] / df['avg_pos_away']\n",
    "df['avg_pos_diff'] = df['avg_pos_home'] - df['avg_pos_away']\n",
    "df['5_form'] = df['home_5_form'] - df['away_5_form']\n",
    "df['3_form'] = df['home_3_form'] - df['away_3_form']\n",
    "df['1_form'] = df['home_1_form'] - df['away_1_form']\n",
    "X, y = prep(df)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a7f0441",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = joblib.load('Models/combined_linear.pk1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee7209e",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def plot_learning_curve(n, est, xs, ys, title):\n",
    "    train_sizes, train_scores, valid_scores = learning_curve(estimator = est, X = xs, y = ys, cv = n, scoring=scorer)\n",
    "\n",
    "    train_mean = np.mean(train_scores, axis=1)\n",
    "    valid_mean = np.mean(valid_scores, axis=1)\n",
    "\n",
    "    plt.plot(train_sizes, train_mean, color='blue', label='Training score')\n",
    "    plt.plot(train_sizes, valid_mean, color='green', label='Validation score')\n",
    "\n",
    "    plt.xlabel('Dataset size')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492e04e5",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def plot_cf(model, X_train, y_train, X_test, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    plot_confusion_matrix(model, X_test, y_test)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5d60b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "scorer = make_scorer(sklearn.metrics.mean_absolute_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226c5137",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_learning_curve(5, grid.best_estimator_, X_train, y_train, 'Learning Curve')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763ac009",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "plot_cf(grid.best_estimator_, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f21f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree = DecisionTreeClassifier(max_depth=3)\n",
    "dtree.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14109666",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "tree.plot_tree(dtree)\n",
    "plt.rcParams['figure.figsize'] = (30, 20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f7c3d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
